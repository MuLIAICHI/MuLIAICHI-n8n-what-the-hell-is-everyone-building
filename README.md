# n8n Workflow Scraper & Analyzer ğŸš€

A comprehensive tool to scrape and analyze 1000+ n8n workflows from the n8n marketplace to discover trends, popular nodes, and real-world use cases.

## ğŸ“‹ Features

### Data Collection (Scraper)
- âœ… Scrapes all workflows from n8n marketplace
- âœ… Smart pagination handling
- âœ… Rate limiting to avoid API issues
- âœ… Category-based scraping for complete coverage
- âœ… Saves raw data in JSON format
- âœ… Automatic summary statistics

### Data Analysis (Analyzer)
- ğŸ“Š **Most Viewed Workflows** - Discover what's popular
- ğŸ”§ **Most Used Nodes** - See which nodes are essential
- ğŸ¯ **Use Case Categories** - Understand real-world applications
- ğŸ’° **Pricing Analysis** - Free vs paid workflow insights
- ğŸ§© **Complexity Analysis** - Node count distribution and trends
- ğŸ‘¥ **Top Creators** - Most prolific workflow builders
- ğŸ“ˆ **Beautiful Visualizations** - Charts and graphs for all metrics

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Run the Scraper

```bash
python n8n_workflow_scraper.py
```

This will:
- Scrape all available workflows (4600+)
- Save raw data to `n8n_data/raw/`
- Generate summary statistics
- Take approximately 5-10 minutes depending on API response time

### 3. Run the Analysis

```bash
python n8n_workflow_analyzer.py
```

This will:
- Process the scraped data
- Generate comprehensive analysis
- Create visualizations as PNG files
- Save results to `n8n_data/analysis/`

## ğŸ“‚ Project Structure

```
n8n-workflow-analysis/
â”œâ”€â”€ n8n_workflow_scraper.py      # Data collection script
â”œâ”€â”€ n8n_workflow_analyzer.py     # Data analysis script
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ README.md                     # This file
â””â”€â”€ n8n_data/                     # Output directory (created automatically)
    â”œâ”€â”€ raw/                      # Raw scraped data
    â”‚   â”œâ”€â”€ workflows_YYYYMMDD_HHMMSS.json
    â”‚   â””â”€â”€ filters_YYYYMMDD_HHMMSS.json
    â”œâ”€â”€ processed/                # Processed data
    â”œâ”€â”€ analysis/                 # Analysis results
    â”‚   â”œâ”€â”€ analysis_report.json
    â”‚   â”œâ”€â”€ top_viewed_workflows.png
    â”‚   â”œâ”€â”€ top_used_nodes.png
    â”‚   â”œâ”€â”€ top_categories.png
    â”‚   â”œâ”€â”€ pricing_analysis.png
    â”‚   â”œâ”€â”€ complexity_analysis.png
    â”‚   â””â”€â”€ top_creators.png
    â””â”€â”€ summary_YYYYMMDD_HHMMSS.json
```

## ğŸ”§ Advanced Usage

### Scraper Options

#### Scrape Specific Category
```python
from n8n_workflow_scraper import N8nWorkflowScraper

scraper = N8nWorkflowScraper()
workflows, filters = scraper.scrape_all_workflows(
    category='AI',          # Filter by category
    rows_per_page=50,       # Results per page
    max_pages=20            # Limit number of pages
)
scraper.save_data(workflows, filters, prefix='ai_')
```

#### Scrape Multiple Categories
```python
categories = ['AI', 'Marketing', 'Sales', 'Support']
workflows, filters = scraper.scrape_by_categories(
    categories=categories,
    rows_per_page=50
)
scraper.save_data(workflows, filters, prefix='multi_')
```

### Analyzer Options

#### Custom Analysis
```python
from n8n_workflow_analyzer import N8nWorkflowAnalyzer

# Initialize with specific data file
analyzer = N8nWorkflowAnalyzer('n8n_data/raw/workflows_20250109_120000.json')

# Run individual analyses
top_workflows = analyzer.analyze_top_viewed(top_n=50)
top_nodes = analyzer.analyze_node_usage(top_n=100)
categories = analyzer.analyze_categories(top_n=20)

# Or generate full report
report = analyzer.generate_full_report()
```

## ğŸ“Š Sample Outputs

### Top Viewed Workflows
```
TOP 20 MOST VIEWED WORKFLOWS
============================================================
name                                               totalViews  price  node_count  user_name
AI Video Automation Engine - Generate & Pub...           1234     10          23  John Doe
Customer Support Chatbot with GPT-4                       987     15          18  Jane Smith
...
```

### Top Used Nodes
```
TOP 30 MOST USED NODES
============================================================
Node                           Usage Count
Sticky Note                           4315
Edit Fields (Set)                     2318
HTTP Request                          2277
Code                                  2166
AI Agent                              2120
...
```

### Node Categories (Real Use Cases)
```
TOP 15 NODE CATEGORIES (Use Cases)
============================================================
Category                       Usage Count
AI                                    4617
Multimodal AI                         2498
Marketing                             1717
AI Summarization                      1294
Content Creation                      1081
...
```

## ğŸ“ˆ Analysis Insights You'll Get

1. **Popularity Metrics**
   - Which workflows get the most views
   - Correlation between complexity and popularity
   - Price vs views analysis

2. **Node Usage Patterns**
   - Essential nodes every workflow uses
   - Specialized nodes for specific use cases
   - Node combinations that work well together

3. **Use Case Distribution**
   - Most common workflow categories
   - Emerging trends (AI, automation, etc.)
   - Niche applications

4. **Creator Insights**
   - Most prolific workflow creators
   - Verified vs community creators
   - Quality indicators

5. **Complexity Analysis**
   - Simple vs complex workflows
   - Average node count
   - Complexity sweet spots

6. **Pricing Trends**
   - Free vs paid distribution
   - Price ranges and averages
   - Value indicators

## ğŸ¯ Use Cases for This Tool

### For n8n Content Creators (Like You!)
- **Content Ideas**: See what topics get the most views
- **Tutorial Planning**: Focus on most-used nodes
- **Market Gaps**: Find underserved categories
- **Pricing Strategy**: Understand market pricing

### For n8n Users
- **Learning Path**: Start with most common nodes
- **Best Practices**: Study popular workflows
- **Use Case Discovery**: Find workflows for your needs
- **Quality Signals**: Identify trusted creators

### For Business/Product Analysis
- **Market Research**: Understand n8n ecosystem
- **Feature Priorities**: See what users build most
- **Integration Opportunities**: Popular tool combinations
- **Competitive Analysis**: Compare your workflows

## ğŸ” API Endpoint Details

The scraper uses the n8n marketplace API:
```
https://n8n.io/api/product-api/workflows/search
```

### Parameters:
- `category` - Filter by category (optional)
- `rows` - Results per page (1-100)
- `page` - Page number (1-N)

### Response Structure:
```json
{
  "totalWorkflows": 4617,
  "workflows": [...],
  "filters": [...]
}
```

## âš ï¸ Important Notes

1. **Rate Limiting**: The scraper includes 1.5s delays between requests to be respectful to the API
2. **Data Size**: Full scrape generates ~50-100MB of JSON data
3. **Processing Time**: 
   - Scraping: 5-10 minutes for all workflows
   - Analysis: 30-60 seconds
4. **Updates**: Re-run scraper periodically to get latest data

## ğŸ› Troubleshooting

### Connection Issues
```python
# Increase delay between requests
scraper.fetch_page(delay=3.0)  # 3 seconds instead of 1.5
```

### Memory Issues
```python
# Scrape in smaller batches
workflows, filters = scraper.scrape_all_workflows(max_pages=50)
```

### Analysis Errors
```bash
# Make sure you ran scraper first
ls -la n8n_data/raw/

# Check data file exists
python -c "import json; json.load(open('n8n_data/raw/workflows_*.json'))"
```

## ğŸ“ Data Fields Reference

Each workflow contains:
- `id` - Unique identifier
- `name` - Workflow title
- `totalViews` - View count
- `price` - Price in USD (0 for free)
- `user` - Creator information
- `description` - Full description
- `nodes` - Array of node objects
- `createdAt` - Creation timestamp
- `purchaseUrl` - Gumroad link

## ğŸš€ Next Steps & Ideas

1. **Time-Series Analysis**: Track trends over time
2. **Node Relationships**: Which nodes are commonly used together
3. **Success Prediction**: ML model to predict workflow popularity
4. **Recommendation Engine**: Suggest workflows based on user interests
5. **Quality Scoring**: Automated quality assessment
6. **Community Insights**: Creator network analysis

## ğŸ“š For Your Learning Hub

This tool is perfect for your n8nlearninghub.com content:

1. **Tutorial Series**: "Data-Driven n8n Workflow Design"
2. **Case Studies**: Analyze top workflows and explain why they work
3. **Trend Reports**: Monthly updates on n8n ecosystem
4. **Node Deep-Dives**: Focus on most popular nodes
5. **Creator Interviews**: Reach out to top creators

## ğŸ¤ Contributing

This is a starting point! You can extend it to:
- Add more visualizations
- Implement NLP on descriptions
- Create interactive dashboards
- Build comparison tools
- Add export formats (CSV, Excel)

## ğŸ“„ License

Feel free to use this for your n8n Learning Hub content and tutorials!

---

**Happy Analyzing! ğŸ‰**

For questions or improvements, reach out on the r/n8nLearningHub community!
